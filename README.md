## Инструкция
Для запуска кода достаточно заменить путь к папкам содержащим файлы `test.jsonl` и `train.jsonl` из репозитория с датасетом GSM8K.

## Отчёт
К сожалению, не получилось провести сами эксперименты, из-за того, что небыло стабильного соединения с частями модели, которые находилсь не на локальном компьютере.

Для сравнения двух подходов в файле `solution.ipynb` реализованы следующие шаги:
* Сравнение результатов CoT и Self-Consistency в зависимости от количества примеров, поданых модели перед.
* Исследования зависимости результатов Self-Consistency от количества семплированных ответов
* Использование в качестве примеров решений только уравнения без текстового пояснения для CoT и Self-Consistency подходов.

Чтобы хотелось реализовать, но не хватило времени:
* Исследование ответов CoT и Self-Consistency подходов при zero-shot promting с явной просьбой к модели выдать обоснованное решение задачи.
* Исследовать зависимость результатов от параметров модели, задаваемых во время генерации

Исходя из схожести модели с GPT-3 (по крайней мере в размерах), можно предположить, что результаты должны совпасть с представленными в статье, то есть можно ожидать прирост точности ответов порядка 15%.
